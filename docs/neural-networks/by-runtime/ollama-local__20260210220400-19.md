---
id: 20260210220400-19
title: "Рантайм: Ollama Local"
summary: "Все модели, работающие локально через Ollama (localhost:11434)"
type: index
status: active
tags: [ai/llm, ai/embedding, content/index]
source: roman
ai_weight: normal
created: 2026-02-10
updated: 2026-02-10
---
# Рантайм: Ollama Local

Все модели, установленные и работающие локально через Ollama на iMac Pro 2017.

## Endpoint

- **URL:** `http://localhost:11434`
- **Конфигурация:** `~/.ollama/`
- **Данные моделей:** `~/.ollama/models/`

## Установленные модели

| Модель | Параметры | Размер | Тип | Назначение | Карточка |
|--------|----------|--------|-----|-----------|---------|
| qwen3:30b | 30B | 18 GB | LLM | Основная, русский | [[cards/qwen3-30b__20260210220400-01\|Qwen3 30B]] |
| qwen3-coder:30b | 30B | 18 GB | LLM | Кодинг | [[cards/qwen3-coder-30b__20260210220400-02\|Qwen3 Coder 30B]] |
| deepseek-r1:8b | 8B | 5.2 GB | LLM | Reasoning | [[cards/deepseek-r1-8b__20260210220400-03\|DeepSeek R1 8B]] |
| llama3.1:8b | 8B | 4.9 GB | LLM | Баланс | [[cards/llama31-8b__20260210220400-04\|Llama 3.1 8B]] |
| nomic-embed-text | 137M | 274 MB | Embedding | Семантический поиск | [[cards/nomic-embed-text__20260210220400-05\|Nomic Embed Text]] |
| qwen2.5-coder:1.5b | 1.5B | 986 MB | LLM | Autocomplete | [[cards/qwen25-coder-15b__20260210220400-06\|Qwen 2.5 Coder 1.5B]] |

## Суммарное потребление

| Метрика | Значение |
|---------|---------|
| Общий размер на диске | ~47.3 GB |
| Количество моделей | 6 |
| Машина | iMac Pro 2017 (macOS) |

## Команды Ollama

```bash
# Список установленных моделей
ollama list

# Запустить модель в интерактивном режиме
ollama run qwen3:30b
ollama run qwen3-coder:30b
ollama run deepseek-r1:8b
ollama run llama3.1:8b
ollama run qwen2.5-coder:1.5b

# Скачать новую модель
ollama pull <model_name>

# Удалить модель (освобождение места)
ollama rm <model_name>

# Проверить статус Ollama
curl http://localhost:11434/api/tags

# Сгенерировать ответ через API
curl http://localhost:11434/api/generate -d '{
  "model": "qwen3:30b",
  "prompt": "Привет!"
}'

# Получить эмбеддинги
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "текст для векторизации"
}'
```

## Интеграция с инструментами

| Инструмент | Как подключён | Конфигурация |
|------------|--------------|-------------|
| Continue (IDE) | Прямое подключение к localhost:11434 | `~/.continue/config.yaml` |
| Dify | API подключение | dify.fingroup.ru -> localhost:11434 |

## Требования к системе

| Ресурс | Минимум | Рекомендуется |
|--------|---------|--------------|
| RAM | 16 GB | 32 GB+ |
| GPU VRAM | 16 GB | 24 GB+ |
| Диск | 50 GB свободно | 100 GB+ |

---

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Реестр нейросетей]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/openrouter__20260210220400-20|Рантайм: OpenRouter]]
- [[infra_all_instruments/docs/neural-networks/by-type/llm__20260210220400-09|LLM модели]]
- [[infra_all_instruments/docs/neural-networks/by-type/embedding__20260210220400-10|Embedding модели]]
