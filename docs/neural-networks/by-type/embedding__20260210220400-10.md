---
id: 20260210220400-10
title: "Embedding модели"
summary: "Полный индекс embedding-моделей: что такое эмбеддинги, сравнение моделей, влияние языка, ценообразование"
type: index
status: active
tags: [ai/embedding, content/index, ai/rag, ai/vector-search]
source: ai-research
ai_weight: high
created: 2026-02-10
updated: 2026-02-25
---
# Embedding модели

## Что такое embedding (простым языком)

**Embedding (эмбеддинг)** --- это способ превратить текст в набор чисел (вектор), чтобы компьютер мог понимать смысл слов и предложений.

### Аналогия

Представьте, что каждое слово или предложение --- это точка на карте. Близкие по смыслу слова стоят рядом, далёкие по смыслу --- далеко друг от друга:

```
        "кошка" ●  ● "котёнок"
                  ● "кот"

   "автомобиль" ●  ● "машина"
                    ● "транспорт"


               "банкротство" ●  ● "несостоятельность"
                                ● "ликвидация"
```

Только вместо двухмерной карты --- вектор из сотен или тысяч чисел (768, 1024, 3072 и т.д.). Чем больше чисел, тем точнее модель может уловить нюансы смысла.

### Как это работает

1. **Текст подаётся на вход** embedding-модели
2. **Модель возвращает вектор** --- массив чисел фиксированной длины, например `[0.023, -0.156, 0.842, ...]`
3. **Вектор хранится в базе данных** (Qdrant, Weaviate, Chroma, pgvector)
4. **При поиске** запрос пользователя тоже превращается в вектор
5. **Сравниваются расстояния** между векторами --- ближайшие = самые релевантные

### Зачем нужно

| Задача | Как используется |
|--------|-----------------|
| RAG (чатбот по документам) | Поиск релевантных фрагментов для ответа |
| Семантический поиск | Поиск по смыслу, а не по ключевым словам |
| Классификация текстов | Группировка похожих документов |
| Дедупликация | Нахождение почти одинаковых текстов |
| Рекомендации | Подбор похожего контента |

> **Важно:** Embedding-модели НЕ генерируют текст. Они преобразуют текст в числовые векторы для поиска по сходству. Это не LLM!

---

## Влияние языка на выбор модели

### Почему язык критически важен

Embedding-модели обучаются на текстовых данных. Если модель видела мало русского текста при обучении, она плохо понимает русские слова и фразы, даже если формально поддерживает мультиязычность.

### Ключевые факторы для русского языка

| Фактор | Описание |
|--------|----------|
| **Обучающая выборка** | Сколько русского текста модель видела при обучении |
| **Токенизация** | Как модель разбивает русские слова на токены (кириллица дороже --- больше токенов на то же кол-во слов) |
| **Бенчмарки** | Результаты на ruMTEB, MIRACL (Russian), MMTEB |
| **Морфология** | Русский --- флективный язык, одно слово имеет десятки форм |

### Проблема токенизации

Русский текст обычно занимает в 1.5--2x больше токенов, чем английский текст того же объёма. Это означает:
- Выше стоимость обработки у платных API
- Быстрее заканчивается контекстное окно
- Модели с BPE-токенизатором, обученным преимущественно на английском, работают хуже

### Рекомендации по выбору

1. **Если бюджет ограничен и нужен русский** --- BGE-M3 (бесплатная, open-source, хорошие результаты на ruMTEB)
2. **Если нужно лучшее качество для русского через API** --- Jina Embeddings v3 или Cohere embed-multilingual-v3
3. **Если уже используется OpenAI** --- text-embedding-3-large (хорошее качество, но не лучшее для русского)
4. **Если работаете локально (Ollama)** --- BGE-M3 или nomic-embed-text (уже установлена)

---

## Установленные модели

| Модель | Параметры | Размер | Размерность | Контекст | Языки | Скорость | Используется в | Карточка |
|--------|----------|--------|:-----------:|:--------:|-------|:--------:|---------------|---------|
| nomic-embed-text | 137M | 274 MB | 768 | 8192 | Multi (вкл. русский) | 10/10 | Continue, Dify | [[cards/nomic-embed-text__20260210220400-05\|Nomic Embed Text]] |
| Qwen3-Embedding-8B | 8B | API | 4096 | 32768 | 100+ языков | 10/10 | mcp-kb-server.py, kb-indexer.py **(ОСНОВНАЯ с 2026-02-25, через DeepInfra API)** | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |

## Применение

| Инструмент | Функция | Модель |
|------------|---------|--------|
| Continue (IDE) | @codebase - поиск по коду | nomic-embed-text |
| Continue (IDE) | @docs - поиск по документации | nomic-embed-text |
| Dify | RAG - retrieval augmented generation | nomic-embed-text |
| mcp-kb-server.py | RAG поиск KB компании (Qdrant) | Qwen3-Embedding-8B (DeepInfra) |
| kb-indexer.py | Индексация документов в Qdrant | Qwen3-Embedding-8B (DeepInfra) |

---

## Сравнительная таблица embedding-моделей

### Облачные (API)

| Модель | Провайдер | Размерность | Контекст | MTEB (en) | Русский (100) | Цена за 1M tok | Free tier | Карточка |
|--------|-----------|:-----------:|:--------:|:---------:|:-------------:|:--------------:|:---------:|---------|
| text-embedding-3-small | OpenAI | 1536 | 8191 | ~62.3 | 60 | $0.02 | Нет | [[cards/openai-text-embedding-3__20260218190000-01\|OpenAI Embed 3]] |
| text-embedding-3-large | OpenAI | 3072 | 8191 | ~64.6 | 65 | $0.13 | Нет | [[cards/openai-text-embedding-3__20260218190000-01\|OpenAI Embed 3]] |
| jina-embeddings-v3 | Jina AI | 1024 | 8192 | ~65.5 | 82 | ~$0.02 | 1M токенов | [[cards/jina-embeddings-v3__20260218190000-02\|Jina Embed v3]] |
| embed-multilingual-v3.0 | Cohere | 1024 | 512 | ~64.5 | 78 | $0.10 | Trial (1000 вызовов/мес) | [[cards/cohere-embed-multilingual-v3__20260218190000-03\|Cohere Embed v3]] |
| embed-v4 | Cohere | 1536 | 512 | ~65.2 | 80 | $0.12 | Trial (1000 вызовов/мес) | --- |
| voyage-3 | Voyage AI | 1024 | 32000 | ~66.0 | 55 | $0.06 | 200M токенов | --- |
| voyage-3.5 | Voyage AI | 1024 | 32000 | ~67.0 | 58 | $0.06 | 200M токенов | --- |
| voyage-multilingual-2 | Voyage AI | 1024 | 32000 | ~63.0 | 72 | ~$0.12 | 50M токенов | --- |
| text-embedding-004 | Google | 768 | 2048 | ~63.0 | 60 | ~$0.00 (free) | Бесплатно | --- |
| gemini-embedding-001 | Google | 3072 | 2048 | ~68.3 | 65 | $0.15 | Free tier | --- |
| Qwen3-Embedding-8B | SiliconFlow (**ОТКЛЮЧЁН** geo-блок) | 4096 | 32768 | ~70.6 | 88 | ~$0.02 | недоступен | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |
| Qwen3-Embedding-8B | DeepInfra (**АКТИВНЫЙ**, осн. с 2026-02-25) | 4096 | 32768 | ~70.6 | 88 | $0.05 | $10.00, auto-topup | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |
| Qwen3-Embedding-8B | Fireworks AI (**РЕЗЕРВ** с 2026-02-25) | 4096 | 32768 | ~70.6 | 88 | $0.10 | $5.00 | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |
| Qwen3-Embedding-8B | Scaleway | 4096 | 32768 | ~70.6 | 88 | ~$0.02 | 1M tokens free | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |
| Qwen3-Embedding-8B | OpenRouter | 4096 | 32768 | ~70.6 | 88 | $0.01 | --- | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |

### Open-source (можно запустить локально)

| Модель | Провайдер | Параметры | Размерность | Контекст | MTEB (en) | Русский (100) | Лицензия | Карточка |
|--------|-----------|:---------:|:-----------:|:--------:|:---------:|:-------------:|:--------:|---------|
| BGE-M3 | BAAI | 568M | 1024 | 8192 | ~63.0 | 85 | MIT | [[cards/bge-m3__20260218190000-04\|BGE-M3]] |
| multilingual-e5-large | Microsoft | 560M | 1024 | 512 | ~61.5 | 80 | MIT | --- |
| jina-embeddings-v3 | Jina AI | 570M | 1024 | 8192 | ~65.5 | 82 | cc-by-nc-4.0 | [[cards/jina-embeddings-v3__20260218190000-02\|Jina Embed v3]] |
| nomic-embed-text-v1.5 | Nomic AI | 137M | 768 | 8192 | ~59.4 | 55 | Apache-2.0 | [[cards/nomic-embed-text__20260210220400-05\|Nomic Embed Text]] |
| Qwen3-Embedding-8B | Alibaba | 8B | 4096 | 32768 | ~70.6 | 88 | Apache-2.0 | [[cards/qwen3-embedding-8b__20260220190000\|Qwen3-Embedding-8B]] |

### Бесплатные API-провайдеры

| Провайдер | Доступные модели | Ограничения | Статус |
|-----------|-----------------|-------------|--------|
| SiliconFlow | BGE-M3, Qwen3-Embedding-8B, bge-large-zh | $1 free credits; BGE-M3 бесплатно | **ОТКЛЮЧЁН** (HTTP 403, geo-блок с 2026-02-24) |
| DeepInfra | Qwen3-Embedding-8B, BGE-M3 и другие | $0.05/1M, $10.00 баланс, auto-topup | **ОСНОВНОЙ (с 2026-02-25)** |
| Fireworks AI | Qwen3-Embedding-8B, nomic-embed-text | $0.10/1M, $5.00 баланс | **РЕЗЕРВ (с 2026-02-25)** |
| Scaleway | Qwen3-Embedding-8B, BGE-M3 | 1M free tokens (навсегда) | active |
| OpenRouter | Qwen3-Embedding-8B и другие | Самый дешёвый $0.01/1M tokens | active |
| Google AI Studio | text-embedding-004, gemini-embedding-001 | Бесплатно с лимитами по RPM | active |
| Ollama (локально) | nomic-embed-text, BGE-M3, all-minilm | Бесплатно, нужно оборудование | active |

---

## Подробное ценообразование

### OpenAI

| Модель | Стандарт (1M tok) | Batch (1M tok) | Размерность | Контекст |
|--------|:-----------------:|:--------------:|:-----------:|:--------:|
| text-embedding-3-small | $0.02 | $0.01 | 1536 (настр. до 256) | 8191 |
| text-embedding-3-large | $0.13 | $0.065 | 3072 (настр. до 256) | 8191 |
| text-embedding-ada-002 (legacy) | $0.10 | $0.05 | 1536 | 8191 |

- **Free tier:** Нет (только $5 стартовых кредитов для новых аккаунтов, расходуются на всё API)
- **Оплата:** За входные токены, выходные не тарифицируются
- **Batch API:** Скидка 50%, результат в течение 24 часов

### Jina AI

| Модель | Цена (1M tok) | Размерность | Контекст |
|--------|:-------------:|:-----------:|:--------:|
| jina-embeddings-v3 | ~$0.02 | 1024 (настр. до 32) | 8192 |
| jina-embeddings-v4 | ~$0.02 | 1024 | 32768 |

- **Free tier:** 1M токенов бесплатно с каждым новым API-ключом (некоторые источники указывают до 10M)
- **Оплата:** По факту использования
- **Примечание:** Новая ценовая модель с мая 2025; старые ключи могут иметь другие цены
- **Локальный запуск:** jina-embeddings-v3 доступна на HuggingFace, но лицензия cc-by-nc-4.0 (некоммерческая)

### Cohere

| Модель | Цена (1M tok) | Размерность | Контекст |
|--------|:-------------:|:-----------:|:--------:|
| embed-multilingual-v3.0 | $0.10 | 1024 | 512 |
| embed-english-v3.0 | $0.10 | 1024 | 512 |
| embed-v4 (текст) | $0.12 | 1536 | 512 |
| embed-v4 (изображения) | $0.47 | 1536 | --- |

- **Free tier (Trial key):**
  - 1000 API-вызовов в месяц (на все endpoints суммарно)
  - Rate limit: 100 вызовов Embed/мин (текст), 5/мин (изображения)
  - Нельзя использовать в production
- **Production:** Оплата по факту, цены выше
- **Примечание:** Trial ключ хорош для тестирования, но очень ограничен для реальной работы

### Voyage AI (теперь часть MongoDB)

| Модель | Цена (1M tok) | Free tier | Размерность | Контекст |
|--------|:-------------:|:---------:|:-----------:|:--------:|
| voyage-3 | $0.06 | 200M токенов | 1024 | 32000 |
| voyage-3-large | $0.12 | 200M токенов | 1024--2048 | 32000 |
| voyage-3.5 | $0.06 | 200M токенов | 1024 | 32000 |
| voyage-3.5-lite | $0.02 | 200M токенов | 1024 | 32000 |
| voyage-multilingual-2 | ~$0.12 | 50M токенов | 1024 | 32000 |

- **Free tier:** Щедрый! 200M токенов для новых моделей, 50M для мультиязычной v2
- **Batch API:** Скидка ~33%
- **Примечание:** Фокус на английском; мультиязычная модель дороже и с меньшим free tier

### Google

| Модель | Цена (1M tok) | Размерность | Контекст | Платформа |
|--------|:-------------:|:-----------:|:--------:|-----------|
| text-embedding-004 | Бесплатно / $0.10 | 768 | 2048 | Vertex AI / AI Studio |
| gemini-embedding-001 | $0.15 | 3072 | 2048 | Gemini API |
| text-multilingual-embedding-002 | Бесплатно / $0.10 | 768 | 2048 | Vertex AI |

- **Free tier:** text-embedding-004 в Google AI Studio фактически бесплатна
- **Примечание:** text-embedding-004 устаревает (deprecated с ~авг.2025), рекомендуется gemini-embedding-001
- **Ограничение:** Контекст всего 2048 токенов --- мало для длинных документов

### Бесплатные варианты

| Вариант | Модели | Стоимость | Где запускать |
|---------|--------|-----------|---------------|
| Ollama (локально) | nomic-embed-text, BGE-M3, all-minilm | Бесплатно | Свой сервер/ПК |
| SiliconFlow | BGE-M3, Qwen3-Embedding-8B | **ОТКЛЮЧЁН** (HTTP 403 с 2026-02-24) | Облако (Китай) |
| DeepInfra | Qwen3-Embedding-8B, BGE-M3 | $10.00 баланс, auto-topup - **ОСНОВНОЙ** | Облако |
| Fireworks AI | Qwen3-Embedding-8B, nomic-embed-text | $5.00 баланс - **РЕЗЕРВ** | Облако |
| Scaleway | Qwen3-Embedding-8B, BGE-M3 | 1M free tokens (навсегда) | Облако (Европа) |
| OpenRouter | Qwen3-Embedding-8B | $0.01/1M tok (самый дешёвый) | Облако |
| Google AI Studio | text-embedding-004 | Бесплатно с лимитами | Облако Google |
| HuggingFace TEI | Любая open-source | Бесплатно | Свой сервер |

---

## Наши аккаунты (зарегистрированные провайдеры)

> API-ключи хранятся в `.secrets/embedding_api_keys.json`. Не коммитить в репозиторий!

| Провайдер | Статус | Endpoint | Баланс | Зарегистрирован |
|-----------|--------|----------|--------|-----------------|
| SiliconFlow | **discontinued** - заблокирован geo (HTTP 403, китайский провайдер) | api.siliconflow.com/v1/embeddings | $0 (доступ закрыт) | 19.02.2026 |
| DeepInfra | **active (ОСНОВНОЙ провайдер с 2026-02-25)** | api.deepinfra.com/v1/openai/embeddings | $10.00, auto-topup настроен ($10 при < $5) | 20.02.2026 |
| Fireworks AI | **reserve (РЕЗЕРВ с 2026-02-25)** - активировать если DeepInfra недоступен | api.fireworks.ai/inference/v1/embeddings | $5.00 | 20.02.2026 |
| Scaleway | active | api.scaleway.ai/v1/embeddings | 1M tokens free | 20.02.2026 |
| OpenRouter | active | openrouter.ai/api/v1/embeddings | --- | ранее |
| DashScope | excluded | --- | --- | нужен китайский телефон |

## Текущий выбор (с 2026-02-25)

**Активный:** DeepInfra - Qwen3-Embedding-8B + Qwen3-Reranker-8B
**Резерв:** Fireworks AI (те же модели, 2x дороже)
**Отключён:** SiliconFlow (geo-блок)

Причина выбора DeepInfra:
- $0.05/1M vs $0.10/1M у Fireworks - экономия 50%
- Те же модели (Qwen3) - то же доказанное качество P@5=0.96
- $10.00 баланс, auto-topup настроен
- EU датацентры, низкий риск блокировки

RAG Quality: P@5=0.96 (Phase 3: multi-query + RRF + reranker)

---

## Рейтинг моделей для русского языка

Оценки основаны на данных ruMTEB, MIRACL (Russian), MMTEB и экспертных отзывах.

| Место | Модель | Русский (100) | Стоимость | Доступность | Рекомендация |
|:-----:|--------|:-------------:|-----------|-------------|-------------|
| 1 | Qwen3-Embedding-8B | 88 | $0.05/1M (DeepInfra, основной) | Open-source | Лучшее качество. Основной провайдер - DeepInfra (P@5=0.96 доказано) |
| 2 | BGE-M3 | 85 | Бесплатно (локально/SiliconFlow) | Open-source (MIT) | Лучший баланс качество/размер для русского |
| 3 | jina-embeddings-v3 | 82 | ~$0.02/1M tok | API + HuggingFace (nc) | Отличное качество, дешёвый API |
| 4 | Cohere embed-multilingual-v3 | 78 | $0.10/1M tok | Только API | Хорошая мультиязычность, дороже |
| 5 | multilingual-e5-large | 80 | Бесплатно (локально) | Open-source (MIT) | Хорошо, но контекст всего 512 токенов |
| 6 | Cohere embed-v4 | 80 | $0.12/1M tok | Только API | Новее, мультимодальная |
| 7 | voyage-multilingual-2 | 72 | ~$0.12/1M tok | Только API | Большой контекст, но средний русский |
| 8 | OpenAI text-embedding-3-large | 65 | $0.13/1M tok | Только API | Хороший английский, средний русский |
| 9 | gemini-embedding-001 | 65 | $0.15/1M tok | API (Google) | Высокая размерность, средний русский |
| 10 | OpenAI text-embedding-3-small | 60 | $0.02/1M tok | Только API | Дешёвый, но русский слабый |
| 11 | nomic-embed-text-v1.5 | 55 | Бесплатно (локально) | Open-source | Быстрая, маленькая, но русский слабоват |

---

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Реестр нейросетей]]
- [[infra_all_instruments/docs/neural-networks/by-type/llm__20260210220400-09|LLM модели]]
- [[infra_all_instruments/docs/neural-networks/by-provider/nomic-ai__20260210220400-18|Провайдер: Nomic AI]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Рантайм: Ollama Local]]

## История

- **2026-02-10:** Создан базовый индекс
- **2026-02-18:** Полное расширение: добавлены разделы "Что такое embedding", "Влияние языка", сравнительные таблицы, ценообразование, рейтинг для русского языка (ai-research)
- **2026-02-20:** Добавлены провайдеры: DeepInfra, Fireworks AI, Scaleway, OpenRouter. Qwen3-Embedding-8B через API. Секция "Наши аккаунты". Карточка Qwen3-Embedding-8B
- **2026-02-25:** Финальный выбор провайдеров: DeepInfra (основной), Fireworks AI (резерв), SiliconFlow (отключён geo-блок). Добавлена секция "Текущий выбор". Добавлены Qwen3-Reranker-8B и mcp-kb-server.py / kb-indexer.py в применение. P@5=0.96 (Phase 3: multi-query + RRF + reranker)
