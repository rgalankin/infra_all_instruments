---
id: 20260218210000-01
title: "Qwen3-Embedding-8B (Alibaba)"
summary: "SOTA embedding-модель 8B параметров от Alibaba: лучшая для русского языка, Apache-2.0, доступна через множество бесплатных и дешёвых провайдеров"
type: spec
status: active
tags: [ai/embedding, ai/rag, provider/alibaba, ai/multilingual, ai/open-source]
source: ai-research
ai_weight: high
created: 2026-02-18
updated: 2026-02-18
model_family: "Qwen3-Embedding"
model_params: "8B"
provider: "Alibaba Cloud (Qwen team)"
runtime: "ollama-local / dashscope / deepinfra / siliconflow / scaleway / fireworks / openrouter"
installed: false
used_in: []
---
# Qwen3-Embedding-8B (Alibaba)

## Основная информация

- **Семейство:** Qwen3-Embedding (Alibaba Cloud / Qwen team)
- **Параметры:** 8B (самая крупная из линейки; есть также 0.6B и 4B)
- **Архитектура:** Decoder-only transformer, адаптированная для embedding
- **Провайдер:** Alibaba Cloud (DashScope Beijing / Singapore)
- **Рантайм:** Ollama (локально), DashScope API, DeepInfra, SiliconFlow, Scaleway, Fireworks AI, OpenRouter
- **Тип:** Embedding (НЕ LLM)
- **Назначение:** Мультиязычный семантический поиск, RAG, классификация, кластеризация
- **Open-source:** Да (Apache-2.0 --- полностью бесплатно для коммерческого использования!)
- **Можно запустить локально:** Да (нужна мощная GPU)

## Спецификации

| Характеристика | Значение |
|---------------|---------|
| Размерность | 4096 (по умолчанию; настраиваемая) |
| Макс. контекст (токенов) | 32768 |
| Языки | 100+ (включая русский) |
| MTEB (en) avg | ~70.6 |
| Размер модели | ~16 GB (FP16) / ~8 GB (Q8) / ~5 GB (Q4) |
| Лицензия | Apache-2.0 (полностью свободная) |

## Оценки

| Критерий | Оценка | Комментарий |
|----------|:------:|-------------|
| Качество (английский) | 95/100 | SOTA среди open-source embedding-моделей на MTEB |
| Качество (русский) | 88/100 | Лучшая среди всех доступных моделей для русского |
| Мультиязычность | 95/100 | 100+ языков с высоким качеством |
| Скорость (локально) | 3/10 | 8B параметров --- медленная без мощной GPU |
| Стоимость | 9/10 | Open-source + множество бесплатных провайдеров |
| Контекст | 10/10 | 32768 токенов --- один из самых больших контекстов |

## Ценообразование

| Провайдер | Стоимость | Free tier | Примечание |
|-----------|-----------|-----------|-----------|
| Ollama (локально) | $0 | Бесплатно навсегда | Нужна мощная GPU |
| DashScope Beijing | ~$0.07/1M tok (0.0005 CNY/1K) | 1M токенов (90 дней) | Нужен китайский номер |
| DashScope Singapore | $0.07/1M tok | 1M токенов (90 дней) | Международная карта |
| Scaleway | ~0.10 EUR/1M tok | 1M токенов (навсегда) | EU карта |
| DeepInfra | ~$0.05/1M tok | $1.80 кредит (~36M) | Без карты |
| SiliconFlow | ~$0.03-0.05/1M tok | $1 кредит (~20M) | Нужен китайский номер |
| Fireworks AI | $0.10/1M tok | $1 кредит (~10M) | Карта после |
| OpenRouter (Nebius) | $0.01/1M tok | Нет | Без карты |

---

## Бесплатные и дешёвые провайдеры (стэкинг free tier)

### Сводная таблица

| # | Провайдер | Бесплатно токенов | Тип | Цена после | Регистрация | Маршрут из РФ |
|:-:|-----------|:-----------------:|:---:|:----------:|-------------|:-------------:|
| 1 | DashScope Beijing | 1M | Разовый (90 дней) | ~0.0005 CNY/1K | Китайский номер | Прямой (Китай) |
| 2 | DashScope Singapore | 1M | Разовый (90 дней) | $0.07/1M | Межд. карта | Прямой |
| 3 | Scaleway (Франция) | 1M | Разовый (навсегда) | ~0.10 EUR/1M | EU карта | Прямой (Франция) |
| 4 | DeepInfra | ~36M ($1.80 кредит) | Разовый | ~$0.05/1M | Без карты | Через US VPS |
| 5 | SiliconFlow (Китай) | ~20M ($1 кредит) | Разовый | ~$0.03-0.05/1M | Китайский номер | Прямой (Китай) |
| 6 | Fireworks AI | ~10M ($1 кредит) | Разовый | $0.10/1M | Карта после | Через US VPS |
| 7 | OpenRouter (Nebius) | 0 | --- | $0.01/1M | Без карты | Через US VPS |
| 8 | Ollama (локально) | бесконечно | Бесплатно навсегда | $0 | Свой сервер | Локально |

**Итого free tier стэкинг: ~69M токенов + бесконечно локально.**

### Детали по провайдерам

**DashScope Beijing и Singapore** --- это разные аккаунты (разные регионы Alibaba Cloud). Можно зарегистрироваться на обоих и получить суммарно 2M бесплатных токенов. Beijing требует китайский номер телефона, Singapore --- международную банковскую карту.

**Scaleway** --- 1M токенов навсегда (не истекает!). Однако на free tier действуют жёсткие rate limits: 20 req/min, 50 req/day. Для пакетной обработки не подходит, но для штучных запросов --- идеально.

**DeepInfra** --- программа DeepStart для стартапов даёт до 1B бесплатных токенов. Стоит подать заявку, если проект подходит под критерии.

**SiliconFlow** --- помимо Qwen3-Embedding, некоторые embedding-модели (в частности BGE-M3) доступны бесплатно навсегда через их API. Можно использовать BGE-M3 бесплатно, а Qwen3-Embedding только за кредиты.

### Альтернативные бесплатные embedding-провайдеры

Если Qwen3-Embedding-8B не обязательна и подходят другие модели:

- **Novita AI** --- BGE-M3 бесплатна навсегда через их API
- **Cloudflare Workers AI** --- qwen3-embedding-0.6b (НЕ 8B!) бесплатна, лимит 10K Neurons/день. Мини-версия Qwen3 Embedding, подходит для лёгких задач
- **Google AI Studio** --- text-embedding-004 / gemini-embedding-001 бесплатно с лимитами (100 RPM, 1000 RPD)
- **Voyage AI** --- 200M бесплатных токенов (voyage-3, voyage-3.5)
- **Jina AI** --- до 10M бесплатных токенов (jina-embeddings-v3)

---

## Поддержка русского языка

- **Статус:** Русский --- один из 100+ языков с первоклассной поддержкой
- **ruMTEB:** SOTA среди всех доступных embedding-моделей
- **Токенизация:** Qwen-токенизатор --- эффективнее для кириллицы, чем GPT-2/GPT-4 токенизатор
- **Практика:** По бенчмаркам и отзывам, значительно лучше BGE-M3 для русского текста (88 vs 85 по нашей оценке)

## Запуск через Ollama

```bash
# Установка
ollama pull qwen3-embedding

# Использование (по умолчанию выбирается версия, подходящая по ресурсам)
curl http://localhost:11434/api/embeddings -d '{
  "model": "qwen3-embedding",
  "prompt": "Процедура банкротства физических лиц"
}'
```

> **Внимание:** 8B-версия требует мощную GPU. На слабом оборудовании Ollama может автоматически выбрать меньшую квантизацию. Для VPS без GPU рекомендуется BGE-M3.

## Использование через API (DashScope)

```python
import dashscope
from dashscope import TextEmbedding

# DashScope (Beijing или Singapore)
resp = TextEmbedding.call(
    model="text-embedding-v4",  # = Qwen3-Embedding-8B
    input="Процедура банкротства физических лиц",
    dimension=4096,
    api_key="YOUR_API_KEY"
)
embeddings = resp.output["embeddings"][0]["embedding"]
```

## Использование через API (OpenRouter)

```python
import requests

response = requests.post(
    "https://openrouter.ai/api/v1/embeddings",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "model": "qwen/qwen3-embedding-8b",
        "input": "Процедура банкротства физических лиц"
    }
)
```

## Требования для локального запуска

| Ресурс | Минимум (Q4) | Рекомендуемо (FP16) |
|--------|-------------|---------------------|
| RAM | 8 GB | 24 GB |
| VRAM (GPU) | 6 GB | 16 GB+ |
| Диск | ~5 GB | ~16 GB |
| CPU | 8 ядер | 16+ ядер (если без GPU) |

> На VPS Beget с 4-8 GB RAM запуск 8B-модели нецелесообразен. Рекомендуется BGE-M3 для локального запуска, а Qwen3-Embedding-8B --- через API.

## Линейка Qwen3-Embedding

| Модель | Параметры | Размерность | Контекст | Когда выбирать |
|--------|:---------:|:-----------:|:--------:|---------------|
| Qwen3-Embedding-0.6B | 0.6B | 2048 | 32768 | Лёгкие задачи, edge devices, Cloudflare Workers |
| Qwen3-Embedding-4B | 4B | 2560 | 32768 | Баланс качество/скорость |
| **Qwen3-Embedding-8B** | **8B** | **4096** | **32768** | **Максимальное качество** |

## Когда выбирать

- **Выбирать, если:** Нужно лучшее качество для русского языка; есть доступ к GPU или бюджет на API; нужен контекст до 32K токенов; нужна Apache-2.0 лицензия для коммерции
- **НЕ выбирать, если:** Нужна высокая скорость (BGE-M3 быстрее); сервер слабый (<8 GB RAM); бюджет нулевой и нет GPU (использовать BGE-M3 через SiliconFlow/Novita AI бесплатно)

## Альтернативы

| Модель | Отличие |
|--------|---------|
| BGE-M3 | В 14 раз меньше (568M), быстрее, бесплатна через Novita AI, но ниже качество русского (85 vs 88) |
| Jina Embeddings v3 | Похожий размер, хорошее качество, но cc-by-nc-4.0 лицензия (не для коммерции) |
| nomic-embed-text-v1.5 | В 58 раз меньше (137M), самая быстрая, но русский слабый (55) |
| OpenAI text-embedding-3-large | Только API, дороже ($0.13/1M), русский средний (65) |

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/by-type/embedding__20260210220400-10|Embedding модели (индекс)]]
- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Реестр нейросетей]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Рантайм: Ollama Local]]
- [[infra_all_instruments/docs/infrastructure/smart-embedding-router__20260218220000-01|Smart Embedding Router]]

## История

- **2026-02-18:** Создана карточка с полным описанием провайдеров и free tier стэкинга (ai-research)
