---
id: qwen3-embedding-8b__20260218210000-01
title: "Qwen3-Embedding-8B"
summary: "Лучшая embedding-модель для русского языка (88/100). Apache-2.0, 8B параметров, контекст 32K. API от $0.01/1M токенов."
type: card
status: active
tags: [ai/embedding, ai/model-card, provider/alibaba, provider/openrouter]
source: ai-research
ai_weight: high
created: 2026-02-18
updated: 2026-02-18
model_family: "Qwen3 Embedding"
model_params: "7.57B (8B)"
provider: "Alibaba/BAAI (Qwen team)"
runtime: "ollama-local / huggingface / openrouter / dashscope"
installed: false
used_in: []
---
# Qwen3-Embedding-8B

## Основная информация

- **Семейство:** Qwen3 Embedding
- **Параметры:** 7.57B (8B)
- **Архитектура:** Qwen3 (decoder-based embedding)
- **Провайдер:** Alibaba/BAAI (Qwen team)
- **Рантайм:** Ollama (локально), HuggingFace, OpenRouter, DashScope, DeepInfra, Fireworks AI, SiliconFlow
- **Тип:** Embedding (НЕ LLM)
- **Назначение:** Семантический поиск, RAG, классификация, кластеризация, дедупликация
- **Open-source:** Да (Apache-2.0 --- полностью бесплатно для коммерческого использования!)
- **Можно запустить локально:** Да

## Спецификации

| Характеристика | Значение |
|---------------|---------|
| Размерность | Гибкая: 32--4096 (по умолчанию 1024) |
| Макс. контекст (токенов) | 32768 |
| Языки | Мультиязычная (включая русский) |
| MTEB (en) avg | ~70.6 |
| Русский (ruMTEB) | 88/100 |
| Размер модели (Ollama Q4_K_M) | 4.7 GB |
| RAM при работе | 6--8 GB |
| Лицензия | Apache-2.0 |

## Оценки

| Критерий | Оценка | Комментарий |
|----------|:------:|-------------|
| Качество (английский) | 90/100 | MTEB ~70.6 --- один из лучших результатов среди embedding-моделей |
| Качество (русский) | 88/100 | Лучший результат на ruMTEB среди всех моделей |
| Мультиязычность | 90/100 | Хорошая поддержка множества языков |
| Скорость (GPU) | 7/10 | 8B параметров --- быстро на GPU, медленнее на CPU |
| Скорость (CPU) | 4/10 | 1--3 сек/документ на CPU |
| Стоимость (API) | 9/10 | От $0.01/1M токенов через OpenRouter |
| Стоимость (локально) | 8/10 | Бесплатно, но нужно 6--8 GB RAM |

## Ценообразование (API)

| Провайдер | Цена за 1M токенов | Free tier | Примечание |
|-----------|:------------------:|:---------:|-----------|
| OpenRouter | $0.01 | Нет | Самый дешёвый, через Nebius |
| DashScope (Alibaba) | $0.07 | 1M токенов (90 дней) | Официальный API |
| DeepInfra | ~$0.05 | Нет | Хороший вариант |
| Fireworks AI | $0.10 | Нет | Надёжный |
| SiliconFlow | ~$0.05--0.15 | $1 кредит | Китай |
| Replicate | ~$0.001/запрос | Нет | Per-run pricing |

## Запуск через Ollama

```bash
# Установка (8B, 4.7 GB)
ollama pull qwen3-embedding:8b

# Также доступны меньшие варианты:
# ollama pull qwen3-embedding:0.6b  (~400 MB)
# ollama pull qwen3-embedding:4b    (~2.5 GB)

# Использование
curl http://localhost:11434/api/embeddings -d '{
  "model": "qwen3-embedding:8b",
  "prompt": "Процедура банкротства физических лиц"
}'
```

## HuggingFace

- **Репозиторий:** `Qwen/Qwen3-Embedding-8B`
- **GGUF квантизации:** Q8_0, Q6_K, Q5_K_M, Q4_K_M, Q3_K_M
- **Запуск:** Через HuggingFace TEI или transformers

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("Qwen/Qwen3-Embedding-8B")
embeddings = model.encode(
    ["Процедура банкротства физических лиц"],
    normalize_embeddings=True
)
```

## Производительность

| Окружение | Скорость |
|-----------|---------|
| GPU (RTX 4060) через TEI | ~20 мс/запрос |
| GPU (RTX 4060) через Ollama | ~99 мс/запрос |
| CPU | 1--3 сек/документ |
| Apple Silicon (Ollama native) | ~10+ tok/s |

## Требования для локального запуска

| Ресурс | Минимум | Рекомендуемо |
|--------|---------|-------------|
| RAM | 6 GB | 8 GB+ |
| VRAM (GPU) | --- | 8 GB+ |
| Диск | 4.7 GB (Q4_K_M) | 8 GB (FP16) |
| CPU | Любой x86_64 / ARM64 | 8+ ядер |

## Ключевые особенности

- **Лучшая модель для русского языка** --- 88/100 на ruMTEB, значительно опережает конкурентов
- **Контекст 32K** --- самый большой среди embedding-моделей; позволяет эмбеддить целые документы
- **Гибкая размерность (32--4096)** --- можно снизить размерность для экономии места в векторной БД без значительной потери качества
- **Apache-2.0 лицензия** --- полная свобода коммерческого использования
- **Matryoshka Representation Learning** --- уменьшение размерности без существенной потери качества (аналог Matryoshka у OpenAI)
- **MTEB ~70.6** --- один из лучших результатов среди всех embedding-моделей, включая английский

## Поддержка русского языка

- **Статус:** Лучшая модель для русского среди всех embedding-моделей
- **ruMTEB:** 88/100 --- первое место в рейтинге
- **Токенизация:** Эффективная токенизация кириллицы (Qwen-tokenizer)
- **Практика:** Отлично работает с юридическими, бизнес- и техническими текстами на русском

## Когда выбирать

- **Выбирать, если:** Нужно лучшее качество для русского языка; нужен большой контекст (32K); нужна Apache-2.0 лицензия для коммерческого использования; есть 6--8 GB RAM для локального запуска или бюджет от $0.01/1M токенов для API
- **НЕ выбирать, если:** Сервер очень слабый (<6 GB RAM) и нет бюджета на API; нужна максимальная скорость на CPU (BGE-M3 или nomic быстрее); достаточно качества BGE-M3 и не хотите тратить ресурсы на 8B модель

## Альтернативы

| Модель | Отличие |
|--------|---------|
| BGE-M3 | В 14 раз меньше (568M), быстрее, MIT лицензия, но русский 85 vs 88; нет контекста 32K |
| Jina Embeddings v3 | Схожий размер (570M), хороший русский (82), но лицензия cc-by-nc-4.0 |
| nomic-embed-text-v1.5 | В 55 раз меньше (137M), очень быстрая, но русский только 55/100 |
| multilingual-e5-large | Хороший русский (80), MIT, но контекст всего 512 токенов |

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/by-type/embedding__20260210220400-10|Embedding модели (индекс)]]
- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Реестр нейросетей]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Рантайм: Ollama Local]]

## История

- **2026-02-18:** Создана карточка (ai-research)
