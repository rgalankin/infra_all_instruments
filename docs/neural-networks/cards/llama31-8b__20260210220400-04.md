---
id: 20260210220400-04
title: "Llama 3.1 8B"
summary: "Быстрая универсальная модель, баланс качества и скорости"
type: spec
status: active
tags: [ai/llm]
source: roman
ai_weight: normal
created: 2026-02-10
updated: 2026-02-10
model_family: "Llama 3.1"
model_params: "8B"
quantization: "Q4_K_M"
size_gb: 4.9
russian_score: 6
speed_score: 7
provider: "Meta"
runtime: "ollama-local"
installed: true
used_in: [continue]
---
# Llama 3.1 8B

## Основная информация

- **Семейство:** Llama 3.1
- **Параметры:** 8B
- **Квантизация:** Q4_K_M
- **Размер на диске:** ~4.9 GB
- **Провайдер:** Meta (открытая модель)
- **Рантайм:** Ollama (localhost:11434)
- **Тип:** LLM (универсальная текстовая модель)
- **Назначение:** баланс качества и скорости, обработка текстов, альтернативная модель

## Оценки

| Критерий | Оценка | Комментарий |
|----------|:------:|-------------|
| Русский язык | 6/10 | Удовлетворительно; английский значительно лучше |
| Скорость | 7/10 | Быстрая, 8B параметров |
| Код | 6/10 | Средне; для кода лучше qwen3-coder |
| Reasoning | 6/10 | Средне; для reasoning лучше deepseek-r1 |
| OCR | 0/10 | Не поддерживает |

## Где используется

| Инструмент | Роль | Комментарий |
|------------|------|-------------|
| Continue (IDE) | chat (alternative) | Быстрая альтернатива |
| Обработка текстов | text processing | Быстрая обработка |

## Рантайм

- **Endpoint:** `http://localhost:11434`
- **Ollama name:** `llama3.1:8b`
- **Запуск:** `ollama run llama3.1:8b`
- **Требования:** 16 GB RAM
- **Конфигурация Continue:** `~/.continue/config.yaml`

## Альтернативы

| Модель | Отличие |
|--------|---------|
| [[qwen3-30b__20260210220400-01\|qwen3:30b]] | Значительно лучше русский, но медленнее |
| [[deepseek-r1-8b__20260210220400-03\|deepseek-r1:8b]] | Тот же размер, лучше reasoning |
| Meta: Llama 3.3 70B (OpenRouter) | Облачная, значительно мощнее |

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Реестр нейросетей]]
- [[infra_all_instruments/docs/neural-networks/by-type/llm__20260210220400-09|LLM модели]]
- [[infra_all_instruments/docs/neural-networks/by-provider/meta-llama__20260210220400-16|Провайдер: Meta/Llama]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Рантайм: Ollama Local]]

## История

- **2026-02-10:** Создана карточка модели
- **2026-02-01:** Модель установлена как быстрая альтернатива в Continue
