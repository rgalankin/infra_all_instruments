---
id: 20260220190000
title: "Qwen3-Embedding-8B"
status: active
source: ai-research
tags: [ai/embedding, ai/model-card]
type: note
summary: "Карточка embedding-модели Qwen3-Embedding-8B (Alibaba/Qwen): 8B параметров, 4096 размерность, лучший результат для русского языка (88/100)"
ai_weight: high
created: 2026-02-20
updated: 2026-02-20
---
# Qwen3-Embedding-8B

## Основные характеристики

| Параметр | Значение |
|----------|----------|
| Разработчик | Alibaba / Qwen |
| Параметры | 8B |
| Размерность вектора | 4096 |
| Контекст | 32768 tokens |
| Лицензия | Apache-2.0 |
| MTEB (en) | ~70.6 |
| Русский язык (100) | 88 (лучший результат среди всех embedding-моделей) |
| Matryoshka Representation Learning | Да (можно уменьшить размерность без значительной потери качества) |
| Мультиязычность | 100+ языков |
| Тип | Dense + Sparse embedding |

## Почему Qwen3-Embedding-8B

- **Лучшее качество для русского языка** среди всех протестированных embedding-моделей (88/100 vs 85/100 у BGE-M3)
- **Огромный контекст** (32768 tokens) позволяет обрабатывать длинные документы целиком
- **Matryoshka-дизайн** - можно сократить размерность с 4096 до 1024 или 512 с минимальной потерей качества, экономя место в векторной БД
- **Apache-2.0 лицензия** - свободное коммерческое использование
- **Широкая доступность** через множество облачных провайдеров и локально через Ollama

## Доступные провайдеры

| Провайдер | Endpoint | Цена за 1M tok | Free tier |
|-----------|----------|:--------------:|-----------|
| SiliconFlow | api.siliconflow.com/v1/embeddings | ~$0.02 | $1.00 кредитов |
| DeepInfra | api.deepinfra.com/v1/embeddings | ~$0.05 | $1.80 кредитов (~36M tokens) |
| Fireworks AI | api.fireworks.ai/inference/v1/embeddings | ~$0.02 | $5.00 кредитов |
| Scaleway | api.scaleway.ai/v1/embeddings | ~$0.02 | 1M tokens бесплатно (навсегда) |
| OpenRouter | openrouter.ai/api/v1/embeddings | $0.01 | --- |
| Ollama (локально) | localhost:11434/api/embeddings | Бесплатно | Нужно оборудование |

## Интеграция через LLM Router

```
Endpoint: /v1/embeddings
Model: qwen3-embedding-8b
```

Все провайдеры поддерживают OpenAI-совместимый формат `/v1/embeddings`, что позволяет использовать единый интерфейс через LLM Router с автоматическим failover между провайдерами.

## Пример запроса (OpenAI-совместимый формат)

```bash
curl -X POST "https://api.siliconflow.com/v1/embeddings" \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-Embedding-8B",
    "input": "Текст для получения эмбеддинга"
  }'
```

## Сравнение с конкурентами (русский язык)

| Модель | Русский (100) | Параметры | Размерность | Контекст | Стоимость |
|--------|:-------------:|:---------:|:-----------:|:--------:|-----------|
| **Qwen3-Embedding-8B** | **88** | 8B | 4096 | 32768 | Бесплатно / ~$0.02 |
| BGE-M3 | 85 | 568M | 1024 | 8192 | Бесплатно |
| jina-embeddings-v3 | 82 | 570M | 1024 | 8192 | ~$0.02 |
| Cohere embed-v4 | 80 | --- | 1536 | 512 | $0.12 |
| multilingual-e5-large | 80 | 560M | 1024 | 512 | Бесплатно |

## Рекомендация

**Основная embedding-модель для всех RAG-проектов компании.**

Для production-сценариев рекомендуется:
1. **Основной провайдер** - Scaleway (бесплатные 1M tokens навсегда, европейский датацентр)
2. **Fallback** - SiliconFlow или DeepInfra
3. **Для больших объёмов** - Ollama на собственном сервере
4. **Самый дешёвый API** - OpenRouter ($0.01/1M tokens)

При использовании Matryoshka с уменьшенной размерностью (1024 вместо 4096) качество на русском остаётся на уровне ~85/100, что сопоставимо с BGE-M3, но с контекстом в 4 раза больше.

## Links (internal)

- [[infra_all_instruments/docs/neural-networks/by-type/embedding__20260210220400-10|Embedding модели (индекс)]]
- [[infra_all_instruments/docs/neural-networks/cards/bge-m3__20260218190000-04|BGE-M3 (карточка)]]
- [[infra_all_instruments/docs/neural-networks/cards/nomic-embed-text__20260210220400-05|Nomic Embed Text (карточка)]]
