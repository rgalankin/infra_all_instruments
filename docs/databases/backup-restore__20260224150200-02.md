---
id: 20260224150200-02
title: "Бэкапы и восстановление PostgreSQL"
summary: >
  Операционное руководство по бэкапам PostgreSQL: pg_dump, pg_restore, автоматические
  бэкапы, DR procedures. Для Beget, USA, Mac серверов.
type: process
status: active
tags: [eng/database, eng/reliability, process/runbook, platform/postgresql]
source: roman
ai_weight: high
created: 2026-02-24
updated: 2026-02-24
---
# БЭКАПЫ И ВОССТАНОВЛЕНИЕ POSTGRESQL

## ОБЗОР

Стратегия бэкапов:
- **Production (Beget, USA):** автоматические ежедневные бэкапы + Docker volume snapshots
- **Dev (Mac):** бэкапы не нужны (можно пересоздать)

## ТИПЫ БЭКАПОВ

### 1. Логические бэкапы (pg_dump)
**Плюсы:** переносимы между версиями PostgreSQL, читаемы (SQL)
**Минусы:** медленное восстановление больших БД

### 2. Физические бэкапы (Docker volume snapshots)
**Плюсы:** быстрое восстановление, point-in-time recovery
**Минусы:** нельзя перенести между версиями PostgreSQL

### 3. Непрерывная архивация (WAL archiving)
**Плюсы:** point-in-time recovery с точностью до секунды
**Минусы:** сложная настройка (TODO для будущего)

## BEGET RUSSIA — АВТОМАТИЧЕСКИЕ БЭКАПЫ

### Механизм 1: Docker Volume Snapshots

**Статус:** ✅ Настроено через Beget панель управления

**Параметры:**
- Частота: ежедневно в 3:00 AM MSK
- Хранение: 7 дней
- Объём: ~2 GB (все 4 БД)
- Последний бэкап: 2026-02-23 03:00

**Управление:**
- Панель Beget → VPS → Snapshots
- Восстановление: создать новый VPS из snapshot

### Механизм 2: pg_dumpall (ручной)

**Скрипт для ручного бэкапа:**
```bash
#!/bin/bash
# /opt/infra/scripts/backup-postgres.sh

BACKUP_DIR="/opt/infra/backups/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
FILENAME="all_databases_$DATE.sql.gz"

# Создать директорию
mkdir -p "$BACKUP_DIR"

# Дамп всех БД
docker exec postgres pg_dumpall -U postgres | gzip > "$BACKUP_DIR/$FILENAME"

# Удалить старые бэкапы (>14 дней)
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +14 -delete

echo "Backup completed: $FILENAME"
echo "Size: $(du -h $BACKUP_DIR/$FILENAME | cut -f1)"
```

**Запуск вручную:**
```bash
ssh roman@82.202.129.193
bash /opt/infra/scripts/backup-postgres.sh
```

**Настроить cron (опционально):**
```bash
# Добавить в crontab
0 3 * * * /opt/infra/scripts/backup-postgres.sh >> /var/log/postgres-backup.log 2>&1
```

## BEGET RUSSIA — ВОССТАНОВЛЕНИЕ

### Сценарий 1: Восстановить одну таблицу

**Шаг 1:** Создать бэкап конкретной таблицы
```bash
docker exec postgres pg_dump -U postgres -d credoserv_chat -t users > users_backup.sql
```

**Шаг 2:** Восстановить таблицу
```bash
docker exec -i postgres psql -U postgres -d credoserv_chat < users_backup.sql
```

### Сценарий 2: Восстановить одну БД

**Шаг 1:** Создать бэкап БД
```bash
docker exec postgres pg_dump -U postgres credoserv_chat > credoserv_chat_backup.sql
```

**Шаг 2:** Удалить БД (если нужно пересоздать)
```bash
docker exec postgres psql -U postgres -c "DROP DATABASE credoserv_chat;"
docker exec postgres psql -U postgres -c "CREATE DATABASE credoserv_chat;"
```

**Шаг 3:** Восстановить БД
```bash
docker exec -i postgres psql -U postgres -d credoserv_chat < credoserv_chat_backup.sql
```

### Сценарий 3: Полное восстановление (Disaster Recovery)

**Если полностью потеряли сервер:**

**Шаг 1:** Создать новый VPS из Beget snapshot
- Панель Beget → Snapshots → Restore to new VPS

**Шаг 2:** Проверить целостность
```bash
ssh roman@<NEW_IP>
docker ps | grep postgres
docker exec postgres psql -U postgres -c "\l"
```

**Если snapshot недоступен, восстановить из pg_dump:**

**Шаг 1:** Развернуть новый PostgreSQL
```bash
cd /opt/infra/compose/postgres
docker-compose up -d
```

**Шаг 2:** Восстановить из бэкапа
```bash
gunzip -c /opt/infra/backups/postgres/all_databases_YYYYMMDD_HHMMSS.sql.gz | docker exec -i postgres psql -U postgres
```

**Шаг 3:** Проверить данные
```bash
docker exec postgres psql -U postgres -d credoserv_chat -c "SELECT count(*) FROM users;"
```

## USA SERVER — БЭКАПЫ (после deployment)

### Автоматический бэкап в S3

**Скрипт:**
```bash
#!/bin/bash
# /opt/documentoved/scripts/backup-postgres.sh

BACKUP_DIR="/opt/documentoved/backups/postgres"
S3_BUCKET="s3://documentoved-backups"  # Cloudflare R2 or AWS S3
DATE=$(date +%Y%m%d_%H%M%S)
FILENAME="all_databases_$DATE.sql.gz"

mkdir -p "$BACKUP_DIR"

# Дамп всех БД
docker exec postgres pg_dumpall -U postgres | gzip > "$BACKUP_DIR/$FILENAME"

# Загрузить в S3 (шифрование SSE)
aws s3 cp "$BACKUP_DIR/$FILENAME" "$S3_BUCKET/" --sse AES256

# Удалить локальные бэкапы старше 7 дней
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +7 -delete

# Отправить уведомление в B24 (опционально)
curl -X POST https://x-credoserv.bitrix24.ru/rest/44/<WEBHOOK>/im.notify \
  -d "to=1&message=PostgreSQL backup completed: $FILENAME"

echo "Backup completed and uploaded to S3: $FILENAME"
```

**Настроить cron:**
```bash
# Добавить в crontab
0 3 * * * /opt/documentoved/scripts/backup-postgres.sh >> /var/log/postgres-backup.log 2>&1
```

**Настроить S3 credentials:**
```bash
# ~/.aws/credentials
[default]
aws_access_key_id = YOUR_KEY
aws_secret_access_key = YOUR_SECRET

# Для Cloudflare R2:
# ~/.aws/config
[default]
region = auto
endpoint_url = https://YOUR_ACCOUNT_ID.r2.cloudflarestorage.com
```

### Восстановление из S3

```bash
# Скачать последний бэкап
aws s3 cp s3://documentoved-backups/all_databases_YYYYMMDD_HHMMSS.sql.gz /tmp/

# Восстановить
gunzip -c /tmp/all_databases_YYYYMMDD_HHMMSS.sql.gz | docker exec -i postgres psql -U postgres

# Проверить
docker exec postgres psql -U postgres -c "\l"
```

## MAC DOCKER — БЭКАПЫ (опционально)

Обычно не нужны, но если требуется:

**Бэкап:**
```bash
cd /Users/mac/Documents/documentoved
docker exec drive_postgres pg_dump -U admin drive_ml > ~/backups/drive_ml_$(date +%Y%m%d).sql
```

**Восстановление:**
```bash
docker exec -i drive_postgres psql -U admin -d drive_ml < ~/backups/drive_ml_20260224.sql
```

**Полная очистка и пересоздание:**
```bash
docker-compose down -v
docker-compose up -d postgres
# База пересоздана из init.sql
```

## DISASTER RECOVERY PROCEDURES

### DR Drill (тестирование восстановления)

**Цель:** Убедиться, что бэкапы рабочие и можно восстановить данные.

**Частота:** Ежеквартально (каждые 3 месяца)

**Процедура:**
1. Создать тестовый PostgreSQL контейнер
2. Восстановить последний бэкап
3. Проверить целостность данных (SELECT count(*) на критичных таблицах)
4. Измерить время восстановления (RTO)
5. Задокументировать результаты

**Скрипт DR drill:**
```bash
#!/bin/bash
# /opt/infra/scripts/dr-drill-postgres.sh

echo "Starting DR drill for PostgreSQL..."
START_TIME=$(date +%s)

# Скачать последний бэкап
LATEST_BACKUP=$(ls -t /opt/infra/backups/postgres/*.sql.gz | head -1)
echo "Using backup: $LATEST_BACKUP"

# Создать тестовый контейнер
docker run -d --name postgres_dr_test \
  -e POSTGRES_PASSWORD=test \
  -e POSTGRES_USER=postgres \
  postgres:16-alpine

# Ждать готовности
sleep 10

# Восстановить
gunzip -c "$LATEST_BACKUP" | docker exec -i postgres_dr_test psql -U postgres

# Проверить целостность
echo "Checking data integrity..."
docker exec postgres_dr_test psql -U postgres -d credoserv_chat -c "SELECT count(*) FROM users;"
docker exec postgres_dr_test psql -U postgres -d telegram_stories -c "SELECT count(*) FROM telegram_story_posts;"

# Измерить время
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo "DR drill completed in $DURATION seconds"

# Удалить тестовый контейнер
docker stop postgres_dr_test
docker rm postgres_dr_test

# Отправить отчёт в B24
curl -X POST https://x-credoserv.bitrix24.ru/rest/44/<WEBHOOK>/im.notify \
  -d "to=1&message=DR drill completed. RTO: ${DURATION}s. Status: SUCCESS"
```

### Metrics и SLA

| Метрика | Target | Текущее |
|---------|--------|---------|
| RPO (Recovery Point Objective) | 24 часа | 24 часа (ежедневные бэкапы) |
| RTO (Recovery Time Objective) | 4 часа | TBD (нужен DR drill) |
| Частота тестов восстановления | Ежеквартально | TODO |
| Хранение бэкапов | 14 дней | 7 дней (Beget), 14 дней (USA) |

## МОНИТОРИНГ БЭКАПОВ

### Проверка последнего бэкапа

**Beget:**
```bash
ssh roman@82.202.129.193
ls -lth /opt/infra/backups/postgres | head -5
```

**USA (после deployment):**
```bash
aws s3 ls s3://documentoved-backups/ --recursive | tail -10
```

### Alerts

**Настроить уведомления при:**
- Бэкап не выполнился (cron не отработал)
- Размер бэкапа сильно изменился (±50% от среднего)
- Бэкап старше 25 часов (пропущен)

**Скрипт проверки:**
```bash
#!/bin/bash
# /opt/infra/scripts/check-backup-health.sh

LATEST=$(ls -t /opt/infra/backups/postgres/*.sql.gz | head -1)
AGE=$(( $(date +%s) - $(stat -c %Y "$LATEST") ))
MAX_AGE=$((25 * 3600))  # 25 часов

if [ $AGE -gt $MAX_AGE ]; then
  echo "ALERT: Backup is too old ($AGE seconds)"
  # Отправить в B24
  curl -X POST https://x-credoserv.bitrix24.ru/rest/44/<WEBHOOK>/im.notify \
    -d "to=1&message=ALERT: PostgreSQL backup is older than 25 hours!"
fi
```

## BEST PRACTICES

1. **Тестировать восстановление** — бэкап без проверки восстановления не бэкап
2. **Хранить offsite** — для production использовать S3/R2 (не только локально)
3. **Шифровать** — бэкапы в S3 с SSE encryption
4. **Автоматизировать** — cron + мониторинг, не полагаться на ручные действия
5. **Документировать** — RTO/RPO, последний DR drill, изменения в процедурах

## LINKS (INTERNAL)

- [[_index__20260224150000-01|Базы данных — реестр]]
- [[postgres-beget__20260224150100-01|PostgreSQL Beget Russia]]
- [[postgres-usa__20260224150100-02|PostgreSQL ISHosting USA]]
- [[connect-guide__20260224150200-01|Подключение к PostgreSQL]]
- [[monitoring__20260224150200-03|Мониторинг БД]]

## REFS (EXTERNAL)

- PostgreSQL Backup Documentation: https://www.postgresql.org/docs/current/backup.html
- AWS S3 CLI: https://docs.aws.amazon.com/cli/latest/reference/s3/

## ИСТОРИЯ

- 2026-02-24: Создано руководство по бэкапам PostgreSQL. DR procedures задокументированы.
