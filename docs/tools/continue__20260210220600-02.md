---
id: 20260210220600-02
title: "Continue"
summary: >
  AI-слой для IDE (Cursor/VS Code). Подключает Ollama-модели:
  qwen3:30b (chat/edit), llama3.1:8b, qwen2.5-coder:1.5b (autocomplete),
  nomic-embed-text (embeddings). OpenRouter для DeepSeek.
type: spec
status: active
tags: [platform/macos, ai/llm]
source: roman
ai_weight: high
created: 2026-02-10
updated: 2026-02-10
category: "AI → Agent Layer → IDE Extension"
version: "config v1.0.0"
criticality: high
platform: macOS
cost: "freemium"
---
# Continue

## Основная информация

- **Категория:** AI → Agent Layer → IDE Extension
- **Версия конфига:** 1.0.0 (schema v1)
- **Статус:** активно
- **Критичность:** высокая
- **Назначение:** AI-ассистент в IDE, подключение локальных и облачных моделей
- **Платформа:** macOS (расширение для Cursor/VS Code)

## Настройки

### Основные параметры
- Конфигурация: `~/.continue/config.yaml`
- TypeScript конфиг: `~/.continue/config.ts`
- Сессии: `~/.continue/sessions/`
- Индекс: `~/.continue/index/`

### Конфигурация моделей

```yaml
# Основная модель (chat/edit/apply)
- model: qwen3:30b
  provider: ollama
  roles: [chat, edit, apply]
  contextLength: 32768

# Альтернативная
- model: llama3.1:8b
  provider: ollama
  roles: [chat]
  contextLength: 8192

# Autocomplete
- model: qwen2.5-coder:1.5b
  provider: ollama
  role: autocomplete

# Embeddings (@codebase, @docs)
- model: nomic-embed-text
  provider: ollama
  role: embeddings
```

## Модели и AI

| Модель | Провайдер | Роль | Контекст |
|--------|----------|------|:--------:|
| qwen3:30b | Ollama | chat, edit, apply | 32768 |
| llama3.1:8b | Ollama | chat | 8192 |
| qwen2.5-coder:1.5b | Ollama | autocomplete | — |
| nomic-embed-text | Ollama | embeddings | — |
| DeepSeek R1T2 Chimera | OpenRouter | (доступна) | — |

## Функции

| Функция | Описание | Модель |
|---------|---------|--------|
| **Chat** | Диалог с AI в боковой панели | qwen3:30b / llama3.1:8b |
| **Edit** | Редактирование выделенного кода | qwen3:30b |
| **Apply** | Применение AI-предложений | qwen3:30b |
| **Autocomplete** | Автодополнение кода в реальном времени | qwen2.5-coder:1.5b |
| **@codebase** | Семантический поиск по кодовой базе | nomic-embed-text |
| **@docs** | Поиск по документации | nomic-embed-text |

## Связи

### Интеграции
- **Ollama** → localhost:11434 (все локальные модели)
- **OpenRouter** → API (облачные модели)
- **Cursor** → встроенное расширение
- **VS Code** → расширение (доступно)

### Зависимости
- Требует: Ollama (для локальных моделей), API-ключ OpenRouter (для облачных)
- Используется в: Cursor, VS Code

## Проблемы и замечания

- При 30B моделях: 5-10 мин на запрос на iMac Pro (RAM bottleneck)
- Autocomplete с qwen2.5-coder:1.5b быстрый, но качество ограничено

## Links (internal)

- [[infra_all_instruments/registry__20260210220000-01|Registry]]
- [[infra_all_instruments/docs/tools/_index__20260210220000-04|Реестр инструментов]]
- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Нейросети]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Ollama Local]]
- [[infra_all_instruments/docs/tools/cursor__20260201200225|Cursor]] — основная IDE, использует Continue как AI-слой
- [[infra_all_instruments/docs/tools/vscode__20260210220700-01|VS Code]] — альтернативная IDE с поддержкой Continue
- [[infra_all_instruments/docs/tools/ollama__20260210220600-03|Ollama]] — локальный runtime для моделей Continue

## История изменений

- 2026-02-10: Создана карточка (данные из ~/.continue/config.yaml)
