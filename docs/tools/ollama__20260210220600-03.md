---
id: 20260210220600-03
title: "Ollama"
summary: >
  Локальный LLM runtime. v0.15.5, 6 моделей (~47 GB), localhost:11434.
  Используется через Continue, Obsidian, Dify, CLI.
type: spec
status: active
tags: [platform/macos, ai/llm]
source: roman
ai_weight: high
created: 2026-02-10
updated: 2026-02-10
category: "AI → Runtime → Local LLM"
version: "0.15.5"
criticality: high
platform: macOS
cost: "free"
---
# Ollama

## Основная информация

- **Категория:** AI → Runtime → Local LLM
- **Версия:** 0.15.5
- **Статус:** активно
- **Критичность:** высокая
- **Назначение:** локальный inference движок для LLM и embedding моделей
- **Платформа:** macOS (x86_64)
- **Endpoint:** `http://localhost:11434`

## Установленные модели (6)

| Модель | Параметры | Размер | Обновлена | Карточка |
|--------|----------|:------:|-----------|---------|
| qwen3:30b | 30B | 18 GB | 13 дней назад | [[infra_all_instruments/docs/neural-networks/cards/qwen3-30b__20260210220400-01\|→]] |
| qwen3-coder:30b | 30B | 18 GB | 9 дней назад | [[infra_all_instruments/docs/neural-networks/cards/qwen3-coder-30b__20260210220400-02\|→]] |
| deepseek-r1:8b | 8B | 5.2 GB | 9 дней назад | [[infra_all_instruments/docs/neural-networks/cards/deepseek-r1-8b__20260210220400-03\|→]] |
| llama3.1:8b | 8B | 4.9 GB | 2 недели назад | [[infra_all_instruments/docs/neural-networks/cards/llama31-8b__20260210220400-04\|→]] |
| nomic-embed-text | 137M | 274 MB | 2 недели назад | [[infra_all_instruments/docs/neural-networks/cards/nomic-embed-text__20260210220400-05\|→]] |
| qwen2.5-coder:1.5b | 1.5B | 986 MB | 2 недели назад | [[infra_all_instruments/docs/neural-networks/cards/qwen25-coder-15b__20260210220400-06\|→]] |

**Общий размер на диске:** ~47.3 GB

## Настройки

### Основные параметры
- Endpoint: `http://localhost:11434`
- Данные моделей: `~/.ollama/models/`
- Конфигурация: `~/.ollama/`

### API

```bash
# Список моделей
GET /api/tags

# Генерация текста
POST /api/generate  {"model": "qwen3:30b", "prompt": "..."}

# Чат
POST /api/chat  {"model": "qwen3:30b", "messages": [...]}

# Эмбеддинги
POST /api/embeddings  {"model": "nomic-embed-text", "prompt": "..."}
```

## Ограничения на iMac Pro

| Ресурс | Значение | Влияние |
|--------|---------|---------|
| RAM | 32 GB DDR4 ECC | Модели до ~18 GB |
| GPU | Vega 56 8GB HBM2 | Ограниченное Metal-ускорение |
| Процессор | Xeon W 3.2GHz 8-core | CPU inference для 30B: медленно |

- Модели 30B: 5-10 мин на запрос (CPU-bound)
- Модели 8B: секунды на запрос
- Одновременно только одна 30B модель в RAM

## Связи

### Инструменты, использующие Ollama

| Инструмент | Модели | Как подключён |
|------------|--------|--------------|
| Continue (IDE) | все 6 | config.yaml → localhost:11434 |
| Obsidian | qwen3:30b | плагины ollama, textgenerator |
| Dify | через API | dify.fingroup.ru → localhost:11434 |
| CLI | все | `ollama run <model>` |

### Зависимости
- Требует: достаточно RAM и диска
- Используется в: Continue, Obsidian, Dify, CLI, скрипты OCR

## Команды

```bash
ollama list                    # Список установленных моделей
ollama run qwen3:30b          # Интерактивный режим
ollama pull <model>            # Скачать модель
ollama rm <model>              # Удалить модель
ollama show <model>            # Информация о модели
ollama ps                      # Активные модели в RAM
```

## Links (internal)

- [[infra_all_instruments/registry__20260210220000-01|Registry]]
- [[infra_all_instruments/docs/tools/_index__20260210220000-04|Реестр инструментов]]
- [[infra_all_instruments/docs/neural-networks/_index__20260210220000-05|Нейросети]]
- [[infra_all_instruments/docs/neural-networks/by-runtime/ollama-local__20260210220400-19|Ollama Local]]
- [[infra_all_instruments/docs/hardware/imac-pro-2017__20260210220100-01|iMac Pro]]
- [[infra_all_instruments/docs/tools/continue__20260210220600-02|Continue]] — использует Ollama для chat, autocomplete, embeddings
- [[infra_all_instruments/docs/tools/obsidian__20260210220600-01|Obsidian]] — плагины ollama, textgenerator, smart-connections
- [[infra_all_instruments/docs/tools/dify__20260210220600-09|Dify]] — подключена к Ollama для LLM

## История изменений

- 2026-02-10: Создана карточка (данные из `ollama list` + `ollama --version`)
